{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spresultaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = pd.read_csv('D:/sentiment_analysis/dataset/gamma_dataset/maindata.csv')\n",
    "filter = toxic_comments[\"review\"] != \"\"\n",
    "toxic_comments = toxic_comments[filter]\n",
    "toxic_comments = toxic_comments.dropna()\n",
    "toxic_comments_labels = toxic_comments[['rating1','rating2','rating3','rating4','rating5']]\n",
    "\n",
    "X = []\n",
    "sentences = list(toxic_comments[\"review\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "\n",
    "y = toxic_comments_labels.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model._make_predict_function()\n",
    "graph = tf.get_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fdb,model,tokenizer):\n",
    "    xp = [preprocess_text(fdb)]\n",
    "    x_trainp = np.array(xp)\n",
    "    x_trainp = tokenizer.texts_to_sequences(x_trainp)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    maxlen = 200\n",
    "    x_trainp = pad_sequences(x_trainp, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    global sess\n",
    "    global graph\n",
    "    with graph.as_default():\n",
    "        K.set_session(sess)\n",
    "        saved_model = tf.keras.models.load_model('nlp_recent_18012020')\n",
    "        result = saved_model.predict(x_trainp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(result):\n",
    "    l = list(chain.from_iterable(result))\n",
    "    ind = l.index(max(l))\n",
    "    val = ''\n",
    "    ind = ind+1\n",
    "    if(ind==1):\n",
    "        val = '128545'\n",
    "    \n",
    "    elif(ind==2):\n",
    "        val = '128577'\n",
    "    \n",
    "    elif(ind==3):\n",
    "        val = '128528'\n",
    "    \n",
    "    elif(ind==4):\n",
    "        val = '128578'\n",
    "    \n",
    "    else:\n",
    "        val = '128513'\n",
    "    \n",
    "    \n",
    "    return ind,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [20/Jan/2020 23:52:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def show() -> 'html':\n",
    "    return render_template('./page.html',the_title='feedback')\n",
    "\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def sentiment() -> 'html':\n",
    "    value = request.form['ta1'] + \" \" + request.form['ta2'] + \" \" + request.form['ta3'] + \" \" + request.form['ta4'] + \" \" + request.form['g']\n",
    "    prediction = predict(value,saved_model,tokenizer)\n",
    "    print(prediction)\n",
    "    print(prediction.shape)\n",
    "    print(len(prediction))\n",
    "    ind, val = scorer(prediction)\n",
    "    return render_template('./result.html',result = prediction,index = ind,emoji = val)\n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 9 [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "<class 'numpy.ndarray'> (9,) \n",
      " [1 2 3 4 5 6 7 8 9]\n",
      "<class 'numpy.ndarray'> (3, 3) \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "<class 'list'> 9 [1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "a = [1,2,3,4,5,6,7,8,9]\n",
    "print (type(a), len(a), a)\n",
    "npa = np.asarray(a)\n",
    "print (type(npa), npa.shape, \"\\n\", npa)\n",
    "npa = npa.reshape((3, 3))\n",
    "print (type(npa), npa.shape, \"\\n\", npa)\n",
    "a = list(chain.from_iterable(npa))\n",
    "print (type(a), len(a), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
