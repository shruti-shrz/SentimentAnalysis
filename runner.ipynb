{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spresultaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = pd.read_csv('newmaindata.csv')\n",
    "filter = toxic_comments[\"review\"] != \"\"\n",
    "toxic_comments = toxic_comments[filter]\n",
    "toxic_comments = toxic_comments.dropna()\n",
    "toxic_comments_labels = toxic_comments[['rating1','rating2','rating3','rating4','rating5']]\n",
    "\n",
    "X = []\n",
    "sentences = list(toxic_comments[\"review\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "\n",
    "y = toxic_comments_labels.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fe60e03b7900>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# saved_model._make_predict_function()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
     ]
    }
   ],
   "source": [
    "# saved_model._make_predict_function()\n",
    "graph = tf.get_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fdb,tokenizer):\n",
    "    xp = [preprocess_text(fdb)]\n",
    "    x_trainp = np.array(xp)\n",
    "    x_trainp = tokenizer.texts_to_sequences(x_trainp)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    maxlen = 200\n",
    "    x_trainp = pad_sequences(x_trainp, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    global sess\n",
    "    global graph\n",
    "    with graph.as_default():\n",
    "        if 'sess' in locals() and sess is not None:\n",
    "            print('Close interactive session')\n",
    "            sess.close()\n",
    "        K.set_session(sess)\n",
    "        saved_model = tf.keras.models.load_model('new_run_cross')\n",
    "        result = saved_model.predict(x_trainp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(result):\n",
    "    l = list(chain.from_iterable(result))\n",
    "    ind = l.index(max(l))\n",
    "    val = ''\n",
    "    ind = ind+1\n",
    "    if(ind==1):\n",
    "        val = '128545'\n",
    "    \n",
    "    elif(ind==2):\n",
    "        val = '128577'\n",
    "    \n",
    "    elif(ind==3):\n",
    "        val = '128528'\n",
    "    \n",
    "    elif(ind==4):\n",
    "        val = '128578'\n",
    "    \n",
    "    else:\n",
    "        val = '128513'\n",
    "    \n",
    "    \n",
    "    return ind,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_model('nlp86')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/May/2020 16:01:43] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "[2020-05-11 16:02:18,657] ERROR in app: Exception on /feedback [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shruti priya\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Shruti priya\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Shruti priya\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Shruti priya\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Shruti priya\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Shruti priya\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-10-37025e9e3569>\", line 10, in sentiment\n",
      "    prediction = predict(value,tokenizer)\n",
      "  File \"<ipython-input-6-d7967a599734>\", line 12, in predict\n",
      "    with graph.as_default():\n",
      "NameError: name 'graph' is not defined\n",
      "127.0.0.1 - - [11/May/2020 16:02:18] \"\u001b[1m\u001b[35mPOST /feedback HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def show() -> 'html':\n",
    "    return render_template('./page.html',the_title='feedback')\n",
    "\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def sentiment() -> 'html':\n",
    "    value = request.form['ta1'] + \" \" + request.form['ta2'] + \" \" + request.form['ta3'] + \" \" + request.form['ta4'] + \" \" + request.form['g']\n",
    "    prediction = predict(value,tokenizer)\n",
    "#     print(prediction)\n",
    "#     print(prediction.shape)\n",
    "#     print(len(prediction))\n",
    "    ind, val = scorer(prediction)\n",
    "    return render_template('./result.html',result = prediction,index = ind,emoji = val)\n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'VERSION'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2e1b684706ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'VERSION'"
     ]
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
